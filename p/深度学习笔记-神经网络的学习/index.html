<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="deep learning note"><title>深度学习笔记-神经网络的学习</title><link rel=canonical href=https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/><link rel=stylesheet href=https://lunatide.tech/scss/style.min.6a692fd055deae459f2a9767f57f3855ba80cafd5041317f24f7360f6ca47cdf.css><meta property='og:title' content="深度学习笔记-神经网络的学习"><meta property='og:description' content="deep learning note"><meta property='og:url' content='https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/'><meta property='og:site_name' content="LunaTide's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2025-11-17T00:00:00+00:00'><meta property='article:modified_time' content='2025-11-17T00:00:00+00:00'><meta property='og:image' content='https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/pic3.jpg'><meta name=twitter:title content="深度学习笔记-神经网络的学习"><meta name=twitter:description content="deep learning note"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/pic3.jpg'><link rel="shortcut icon" href=https://lunatide.tech/./favicon.ico></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=https://lunatide.tech/><img src=https://lunatide.tech/img/avatar_hu_8b96c345a57a41a4.jpeg width=300 height=297 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>😓</span></figure><div class=site-meta><h1 class=site-name><a href=https://lunatide.tech/>LunaTide's Blog</a></h1><h2 class=site-description>Welcome to my Blog</h2></div></header><ol class=menu-social><li><a href=http://codeforces.com target=_blank title=codeforces rel=me><svg viewBox="0 0 24 24" id="code-forces"><path fill="#F44336" d="M24 19.5V12a1.5 1.5.0 00-1.5-1.5h-3A1.5 1.5.0 0018 12v7.5a1.5 1.5.0 001.5 1.5h3a1.5 1.5.0 001.5-1.5z"/><path fill="#2196F3" d="M13.5 21a1.5 1.5.0 001.5-1.5v-15A1.5 1.5.0 0013.5 3h-3C9.673 3 9 3.672 9 4.5v15c0 .828.673 1.5 1.5 1.5h3z"/><path fill="#FFC107" d="M0 19.5c0 .828.673 1.5 1.5 1.5h3A1.5 1.5.0 006 19.5V9A1.5 1.5.0 004.5 7.5h-3C.673 7.5.0 8.172.0 9v10.5z"/></svg></a></li><li><a href=https://www.zhihu.com target=_blank title=Zhihu rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-zhihu"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14 6h6v12h-2l-2 2-1-2h-1z"/><path d="M4 12h6.5"/><path d="M10.5 6h-5"/><path d="M6 4c-.5 2.5-1.5 3.5-2.5 4.5"/><path d="M8 6v7c0 4.5-2 5.5-4 7"/><path d="M11 18l-3-5"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=https://lunatide.tech/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=https://lunatide.tech/%E5%85%B3%E4%BA%8E/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li><a href=https://lunatide.tech/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=https://lunatide.tech/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=https://lunatide.tech/%E5%8F%8B%E9%93%BE/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>友链</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#从数据中学习>从数据中学习</a><ol><li><a href=#数据驱动>数据驱动</a></li><li><a href=#训练数据和测试数据>训练数据和测试数据</a></li></ol></li><li><a href=#损失函数>损失函数</a><ol><li><a href=#均方误差>均方误差</a></li><li><a href=#交叉熵误差>交叉熵误差</a></li><li><a href=#mini-batch学习>mini-batch学习</a></li><li><a href=#mini-batch版交叉熵误差的实现>mini-batch版交叉熵误差的实现</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/><img src=https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/pic3_hu_7244c689e98ede3c.jpg srcset="https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/pic3_hu_7244c689e98ede3c.jpg 800w, https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/pic3_hu_1ef3c590ecabf062.jpg 1600w" width=800 height=446 loading=lazy alt="Featured image of post 深度学习笔记-神经网络的学习"></a></div><div class=article-details><header class=article-category><a href=https://lunatide.tech/categories/deep-learning/>Deep Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/>深度学习笔记-神经网络的学习</a></h2><h3 class=article-subtitle>deep learning note</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>2025-11-17</time></div></footer></div></header><section class=article-content><h2 id=从数据中学习>从数据中学习</h2><p>神经网络的特征就是从数据中学习（由数据自动决定权重参数的值）</p><h3 id=数据驱动>数据驱动</h3><p>我们接着上一章最后手写数字识别的话题，思考一下会发现如果设计一个能自动识别5的算法还是挺困难的（至少我是这样认为的），所以我们应该考虑通过有效利用数据来解决这个问题，一种方案是从图像中提取特征量，再用机器学习技术学习这些特征量的模式</p><p>机器学习的方法中，由机器从收集到的数据中找到规律性。但是将图像转换为向量时使用的特征量仍是由人设计的，对于不同的问题，必须使用合适的特征量，才能得到好的结果</p><p>还有一种是神经网络（深度学习）的方法，该方法不存在人为介入，神经网络会直接学习图像本身</p><h3 id=训练数据和测试数据>训练数据和测试数据</h3><p>机器学习中把数据分成训练数据和测试数据两部分，首先用训练数据进行学习，寻找最优的参数，然后用测试数据评价训练得到的模型的实际能力，为了正确评价模型的泛化能力，就必须划分训练数据和测试数据，训练数据也被称作<strong>监督数据</strong></p><p>泛化能力是指处理未被观察过的数据的能力。机器学习的目标就是为了提高泛化能力</p><p>因此，仅仅用一个数据集去学习和评价参数，无法正确评价，只用某个数据集过度拟合的状态称为过拟合</p><h2 id=损失函数>损失函数</h2><p>神经网络的学习通过某个指标来表示现在的状态。然后以这个指标为基准，寻找最优权重参数。这个指标被称为<strong>损失函数</strong>。损失函数可以使用任意参数，但一般用均方误差和交叉熵误差等。</p><h3 id=均方误差>均方误差</h3><p>如下式</p>$$
E = \frac{1}{2} \sum_k (y_k - t_k) ^ 2 \tag{1}
$$<p>这里$y_k$是表示神经网络的输出，$t_k$是表示监督数据，$k$表示数据的维数，如式(1)所示，均方误差会计算神经网络的输出和正确解监督数据的各个元素之差的平方，再求总和。python实现均方误差的实现方式如下所示</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>mean_squared_error</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>t</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=mf>0.5</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>((</span><span class=n>y</span> <span class=o>-</span> <span class=n>t</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=交叉熵误差>交叉熵误差</h3><p>交叉熵误差如下式所示</p>$$
E = - \sum_k (t_k \log{y_k}) \tag{2}
$$<p>$y_k$是神经网络的输出，$t_k$是正确解标签(采用one-hot表示)。交叉熵误差的值是由正确解标签所对应的输出结果决定的。</p><p>根据对数函数的性质我们可以知道，正确解标签对应的输出越大，式(2)的值就越靠近0；输出为1时，交叉熵的误差为0。如果正确解标签对应的输出较小，(2)的值就越大。</p><p>下面实现一下交叉熵误差</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>cross_entropy_error</span><span class=p>(</span><span class=n>y</span><span class=p>,</span><span class=n>t</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>delta</span> <span class=o>=</span> <span class=mi>1</span><span class=n>e</span> <span class=o>-</span> <span class=mi>7</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>t</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>y</span> <span class=o>+</span> <span class=n>delta</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>y和t在这里是NumPy数组，加上一个delta是为了防止-inf的发生</p><h3 id=mini-batch学习>mini-batch学习</h3><p>前面说的都是单个数据的损失函数。如果要求所有训练数据的损失函数的总和，以交叉熵误差为例，可以写成下面的式(3)</p>$$
E = -\frac{1}{N} \sum_{n} \sum_{k} t_{nk}\,\log y_{nk} \tag{3}
$$<p>假设一共有N个数据，$t_{nk}$表示第n个数据的第k个元素的值</p><p>这个式子就是把单个数据的损失函数的式扩大到了N份数据，不过最后还要除以N进行正规化。</p><p>MNIST数据集的训练数据有60000个，用全部数据来计算损失函数的值所花费的时间太长，所以我们从中选取一部分。神经网络的学习也是从训练数据中选出一批数据（称为mini-batch)，然后对每个mini-batch进行学习。</p><h3 id=mini-batch版交叉熵误差的实现>mini-batch版交叉熵误差的实现</h3><p>对于mini-batch的交叉熵误差，只要改良一下之前实现对应单个数据的交叉熵误差就可以。这里实现一个可以同时处理单个数据和批量数据两种情况的函数</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>cross_entropy_error</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>t</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>y</span><span class=o>.</span><span class=n>ndim</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>t</span> <span class=o>=</span> <span class=n>t</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=n>t</span><span class=o>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=n>y</span><span class=o>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>  <span class=n>batch_size</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=p>,</span><span class=n>log</span><span class=p>(</span><span class=n>y</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>batch_size</span><span class=p>),</span><span class=n>t</span><span class=p>]</span> <span class=o>+</span> <span class=mi>1</span><span class=n>e</span> <span class=o>-</span> <span class=mi>7</span><span class=p>))</span> <span class=o>/</span> <span class=n>batch_size</span>
</span></span></code></pre></td></tr></table></div></div><p>这里，y是神经网络的输出，t是监督数据。y的维度为1时，即求单个数据的交叉熵误差时，需要改变数据的形状。并且，当输入为mini-batch时，要用batch的个数进行正规化，计算单个数据的平均交叉熵误差</p><p>此外，当监督数据时标签形式(非one-hot表示，而是像"2" &ldquo;7"这样的)交叉熵误差可以如下实现</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>cross_entropy_error</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>t</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>y</span><span class=o>.</span><span class=n>ndim</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>t</span> <span class=o>=</span> <span class=n>t</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=n>t</span><span class=o>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=n>y</span><span class=o>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>  <span class=n>batch_size</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>y</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>arrange</span><span class=p>(</span><span class=n>batch_size</span><span class=p>),</span><span class=n>t</span><span class=p>]</span> <span class=o>+</span> <span class=mi>1</span><span class=n>e</span> <span class=o>-</span> <span class=mi>7</span><span class=p>))</span> <span class=o>/</span> <span class=n>batch_size</span>
</span></span></code></pre></td></tr></table></div></div></section><footer class=article-footer></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8B/><div class=article-image><img src=https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8B/pic3.ea994d84be7267c39cdac1325390798d_hu_5f7ccc2673021dd8.jpg width=250 height=150 loading=lazy alt="Featured image of post 深度学习笔记-神经网络(下)" data-hash="md5-6plNhL5yZ8Oc2sEyU5B5jQ=="></div><div class=article-details><h2 class=article-title>深度学习笔记-神经网络(下)</h2></div></a></article><article class=has-image><a href=https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8A/><div class=article-image><img src=https://lunatide.tech/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8A/pic3.ea994d84be7267c39cdac1325390798d_hu_5f7ccc2673021dd8.jpg width=250 height=150 loading=lazy alt="Featured image of post 深度学习笔记-神经网络(上)" data-hash="md5-6plNhL5yZ8Oc2sEyU5B5jQ=="></div><div class=article-details><h2 class=article-title>深度学习笔记-神经网络(上)</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 LunaTide's Blog</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=https://lunatide.tech/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>